---
layout: home
permalink: /contest/
title: Seldonian \| Competition
---

<!-- Main Container -->
<div class="container p-3 my-5 border" style="background-color: #f3f4fc;">
<h1 class="mb-2 text-center">Seldonian Toolkit Competition</h1>
    <div class="container p-3 text-center text-secondary" style="background-color: #f3f4fc;">
            <img src="{{ "/assets/img/contest/STC.png" | relative_url }}" class="img-fluid rounded" alt="Seldonian Toolkit Competition Logo" width="25%">
            <br>
            DALL-E's interpretation of "An abstract art painting with hints of technology and safety."
    </div>
<hr class="my-2">
<div class="my-4 text-center"> 
    <a href="https://forms.gle/ffcp9kBaxprjEya76" class="btn btn-primary center-block">Register Now</a>
</div>
<p>
        <b>Announcement.</b> We are happy to announce the first Seldonian Toolkit Competition, a contest that allows undergraduate and graduate students in the US and Canada to learn about and develop safe and fair machine learning algorithms using the recently launched Seldonian Toolkit. This toolkit was created to make it easier for data scientists to apply machine learning responsibly: with high-confidence safety and fairness constraints on the machine learning system's behavior.
    </p>
    <p>
        We welcome people from different fields (not just computer science!) to participate in this competition. Students will have the freedom to select the application and dataset that they work with, allowing them to tackle problems within their own discipline using our machine learning tools and with expert support.
    </p>
    <p>
        <b>Eligibility.</b> Participants may participate individually or in teams of up to three people. All participants must be enrolled at an accredited college or university in the US or Canada at either the undergraduate or graduate (masters or doctoral) level.
    </p>
    <p>
        <b>Fees.</b> There are no fees associated with participating in this contest.
    </p>
    <p>
        <b>Prizes.</b> A prize pool of $2,000 USD will be divided into several different awards, and some of the best submissions will be featured on this website. Additional details are provided below in the section titled "Awards and Evaluation Criteria."
    </p>
    <p>
        <b>Time Commitment.</b> The open-ended nature of this competition means that participants could spend a relatively small amount of time, like a weekend, putting together a submission. However, participants might also devote significant time to their project over the duration of the contest (see Important Dates below). Overall, we anticipate that the most successful teams will spend at least a couple hours per week on the project.
    </p>
    <p>
        <b>Project Topics.</b> This competition is intentionally open ended. This means that instead of us picking a specific dataset or problem for you to solve, <i>you</i> get to pick a topic that you find interesting! For some examples of possible projects, we recommend reviewing the various tutorials and examples that can be found using the links at the top of this page. These include a variety of examples where fairness with respect to properties like age, race, religion, and gender is important. One can also enforce safety constraints by placing accuracy requirements on models, or by defining additional safety related constraints (see for example the safety constraints enforced on a machine learning model for type 1 diabetes treatment, as described in <a href="http://aisafety.cs.umass.edu/paper.html">this</a> paper). Though teams can use the toolkit for supervised learning (regression and classification) applications and reinforcement learning applications, we expect that most applications will focus on supervised learning settings, as the reinforcement learning components of the toolkit are still relatively nascent.
    </p>
    <p>
        To summarize, any application of the toolkit that includes a high-confidence constraint falls within the scope of this competition!
    </p>
    <p> 
        <b>Talks.</b> To help give participants a more complete view of AI safety and fairness topics, we will be inviting speakers who are not working with Seldonian algorithms, but who are still studying issues related to safety and fairness. Tentative speakers include <a href="https://vaelgates.com/">Dr. Vael Gates</a>, <a href="https://people.umass.edu/yzick/">Yair Zick</a>, and Krisztina Filep from University Analytics and Institutional Research at UMass Amherst.
    </p>
    <p>
        <b>Important Dates.</b>
        <ul>
            <li>
                <p>
                    <b>[Early Registration] March 2, 2023</b>: Participating teams should register by midnight (anywhere on Earth) on March 2, 2023. Registration is free and non-binding. Teams can register right now by clicking the button below and filling out the provided form.
                </p>
                <div class="my-4 text-center"> 
                    <a href="https://forms.gle/ffcp9kBaxprjEya76" class="btn btn-primary center-block">Register Now</a>
                </div>
            </li>
            <li style="margin: 10px 0;"><b>[Kick-Off Event] March 6, 2023</b>: This event will consist of:
            <ul>
                <li>Prof. Philip Thomas providing a high-level introduction to AI safety and fairness topics using Seldonian algorithms. </li>
                <li>Dr. Austin Hoag providing coding examples of how the Seldonian Toolkit can be used. </li>
            </ul>  
            This event will be held from 5:30pm - 7:00pm Eastern Time on Zoom (<a href="https://umass-amherst.zoom.us/j/99288787234">link</a>), though participants are welcome to attend in-person at UMass Amherst (CS Building Room 151).</li>
            <li style="margin: 10px 0;">
                <b>[Late Registration] March 10, 2023</b>: Participating teams <b>must</b> register by midnight (anywhere on Earth) on March 10, 2023 in order to be eligible for any awards. Registration is free and non-binding. We strongly encourage teams to register before the March 2 deadline so that they can receive information about the timing and location of the Kick-Off Event. However, registration by March 10 is sufficient to participate in the contest.
            </li>
            <li style="margin: 10px 0;"><b>[Early-Contest Q&A] March 15, 2023</b>: Prof. Philip Thomas and Dr. Austin Hoag will host an open Q&A session for participating teams. Further details for this event will be provided to all registered teams.</li>
            <li style="margin: 10px 0;"><b>[Mid-Contest Q&A] March 27, 2023</b>: Prof. Philip Thomas and Dr. Austin Hoag will host an open Q&A session for participating teams. Further details for this event will be provided to all registered teams.</li>
            <li style="margin: 10px 0;"><b>[Late-Contest Q&A] April 8, 2023</b>: Prof. Philip Thomas and Dr. Austin Hoag will host an open Q&A session for participating teams. Further details for this event will be provided to all registered teams.</li>
            <li style="margin: 10px 0;">
                <b>[Final Submissions] April 21, 2023</b>: Final submissions are due at midnight (anywhere on Earth) on April 21, 2023. See the "Submissions" section below for more information about what should be submitted.
            </li>
            <li style="margin: 10px 0;">
                <b>[Award Announcement] April 28, 2023</b>: We aim to announce the winners of the competition by April 28, 2023. The exact date will depend on the volume of submissions.
            </li>
        </ul>
    </p>
</div>

<div class="container p-3 my-5 border" style="background-color: #f3f4fc;">
    <h3 class="mb-3" id="framework">Participation and Submission</h3>
    <hr class="my-4" />
    <p>
        Participating teams should select an application of the Seldonian Toolkit. While there are no restrictions on the allowed applications, we recommend that you select an application for which you have access to training data and which your team members are familiar with. This could range from predicting how far landslides will travel based on features of the slope, with safety guarantees related to the chance of under-predictions, to predicting whether a tumor is benign or malignant with safety guarantees with respect to the false negative rate, to predicting whether someone will commit a crime in the future while enforcing fairness constraints with respect to race, gender, or age. Some teams might already have applications in mind, while others might begin by brainstorming possible applications. For teams still trying to select an application, we recommend searching for datasets that relate to machine learning problems where safety or fairness guarantees would be beneficial.
    </p>
    <p>
        After selecting an application, teams should apply the Seldonian Toolkit. In almost all cases, teams should use the Experiments component of the toolkit to show how effective the Seldonian Toolkit is for their application. The Experiments component is described in <a href="https://seldonian.cs.umass.edu/Tutorials/tutorials/fair_loans_tutorial/">this</a> tutorial. It provides plots that show how accurate the learned models are, how much data was required before the system could reliably return solutions, and how often the system violated the desired safety or fairness constraints. 
    </p>
    <p>
        Next, teams should put together a report describing their application, its importance, how the Seldonian Toolkit was applied, and the resulting performance of their system. This report should be provided as a markdown (.md) file in a GitHub repository that contains the source code for the project. The markdown file should clearly indicate the team name somewhere near the top. Each team should then fill out the submission form linked below, which asks for a link to the GitHub repository. <a href="https://github.com/mhyeh/Fairness-for-Lie-Detection">This</a> is an example of what a team might submit. 
    </p>
    <div class="col-md-12 text-center"> 
        <a href="https://forms.gle/VXGZ7ynk42hBVS5c9" class="btn btn-primary center-block">Submission Form</a>
    </div>
</div>

<div class="container p-3 my-5 border" style="background-color: #f3f4fc;">
    <h3 class="mb-3" id="framework">Awards and Evaluation Criteria</h3>
    <hr class="my-4" />
    <p> Awards will be provided for the following topics. Evaluation will be subjective and performed by a panel of AI faculty from UMass Amherst (Professors Philip S. Thomas, Bruno Castro da Silva, and Scott Niekum), Stanford University (Professor Emma Brunskill), and Brown University (Professor George Konidaris). Teams can only win one award. Submissions are automatically considered for all awards for which the submitting team is eligible. Submissions using unethically acquired data will be disqualified. </p>
    <ul>
        <li><b>Best Overall Project [$600]</b> Projects will be evaluated based on the potential positive impacts of the proposed application, the performance of the trained system, the feasibility of the proposed application to the real-world, and the clarity and quality of the submitted report and code. All teams are eligible for this award.</li>
        <li><b>Best Overall Project (Undergraduate) [$500]</b> This award is similar to the Best Overall Project, but is restricted to teams that include only undergraduate students. If the winner of the Best Overall Project includes only undergraduate students, the second best project from an all-undergraduate team will win this award.</li>
        <li><b>Most Creative Project [$300]</b> Projects will be evaluated based on the same criteria as the Best Overall Project award, but with a significant emphasis placed on the creativity and novelty of the proposed application. The panel of reviewers each have decades of experience working on AI research and have seen many uses of AI and machine learning. Submissions that are competitive for this award will involve applications that the review panel have not seen before, or which are less common in the AI and ML literature.</li>
        <li><b>Best Runner-Up Application with Fairness Considerations [$300]</b> Projects will be evaluated based on the same criteria as the Best Overall Project award. This award is restricted to projects related to fairness and equality.</li>
        <li><b>Best Runner-Up Application with Safety Considerations [$300]</b> Projects will be evaluated based on the same criteria as the Best Overall Project award. This award is restricted to projects with safety constraints not related to fairness and equality.</li>
    </ul>
</div>

<div class="container p-3 my-5 border" style="background-color: #f3f4fc;">
    <h3 class="mb-3" id="framework">Support</h3>
    <hr class="my-4" />
    <p> Participants are encouraged to post questions on the GitHub issues pages [links: <a href="https://github.com/seldonian-toolkit/Engine/issues">Engine</a>, <a href="https://github.com/seldonian-toolkit/Experiments">Experiments</a>, and <a href="https://github.com/seldonian-toolkit/GUI">GUI</a>]. We will do our best to answer these questions in a timely manner. For questions related to this competition but not directly related to the use of the Seldonian Toolkit, we encourage teams to ask during the kick-off event or the various Q&A sessions held throughout the contest. Teams can also email <a href="mailto:Seldonian@cs.umass.edu">Seldonian@cs.umass.edu</a>. However, responses to these emails may be slow depending on the volume of participants and questions.</p>
    <p>
        The UMass Data Science club has also created a Discord server where participants can interact with each other.
    </p>
    <div class="col-md-12 text-center"> 
        <a href="https://discord.gg/3hsH7mrDCM" class="btn btn-primary center-block">Discord Server</a>
    </div>
</div>

<div class="container p-3 my-5 border" style="background-color: #f3f4fc;">
    <h3 class="mb-3" id="framework">Sponsors</h3>
    <hr class="my-4" />
    <p> This contest is a collaboration between the Autonomous Learning Laboratory (ALL) at the University of Massachusetts and the Berkeley Existential Risk Initiative (BERI). The awards will be provided by BERI.</p>
</div>
